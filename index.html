<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Bayesian score calibration for approximate models</title>
    <meta charset="utf-8" />
    <meta name="author" content="Joshua J Bon" />
    <script src="libs/header-attrs-2.19/header-attrs.js"></script>
    <link href="libs/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link href="libs/remark-css-0.0.1/default-fonts.css" rel="stylesheet" />
    <link href="libs/remark-css-0.0.1/hygge.css" rel="stylesheet" />
    <link rel="stylesheet" href="bon-qut-campus-title.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

.title[
# Bayesian score calibration for approximate models
]
.author[
### Joshua J Bon
]
.institute[
### Queensland University of Technology
]
.date[
### Without Exact Likelihoods ’23
]

---

class: list-space


&lt;style&gt;

.list-space li {
padding: 0.25cm;
}

.list-nobullet li {
  list-style-type:none;
}

&lt;/style&gt;

.pull-left[
Joint work with 

- **Christopher Drovandi**, QUT
- **David Warne**, QUT
- **David Nott**, NUS


Groups

- **School of Mathematical Sciences**, QUT
- **Centre for Data Science**, QUT

Contact

- Twitter: **@bonstats**
- Email: **joshuajbon@gmail.com**

Paper

- https://arxiv.org/abs/2211.05357

]

.pull-right[

&lt;img src="imgs/snow-bike.JPG" height="550" /&gt;


]

---
class: list-space

## Motivation: "Little rascal" likelihoods

.pull-left[
Current methods for **intractable** likelihoods:

- 10,000s of realisations of the data generating process (ABC, pseudo-marginal MCMC)
- May not target the true posterior (ABC)
- How to identify method failure?

]

.pull-right[
![](imgs/little_rascals_our_gang_waiting.gif)&lt;!-- --&gt;
]


--

.center[
.content-box-red[
But we have **approximate** likelihoods/models available...
]]

---
class: list-space

## Motivation: Approximations everywhere

.pull-left[
**Likelihood approximations**
  - Limiting distributions
  - Whittle likelihood
  - Model simplification (e.g. SDE -&gt; ODE)
  - Linear noise approximation
]

--

.pull-right[
**Posterior approximations**
  - Laplace
  - Variational inference
  - ABC
]

--

.pull-right[
**Sampling approximations**
  - Importance sampling
  - MCMC (MH, ULA, MALA, HMC)
]

---
class: list-space

## Motivation

- Fast approximate model `\(\hat\pi(\theta~\vert~y)\)` known to be biased, data simulation is expensive
- Correct the bias (average over `\(\theta\)`) using simulation


--

.pull-left[
.content-box-blue[
**Simulate the posterior fitting process**
&lt;br&gt;
1. Draw from prior `\(\bar\theta_m \sim \Pi\)`
2. Draw new data `\(\tilde{y}_m \sim P(~\cdot~\vert~\theta_m)\)`
3. Sample posterior `\((\theta_i \vert \tilde{y}_m) \sim \hat{\pi}(~\cdot~\vert~\tilde{y}_m)\)`
&lt;br&gt;
for `\(m \in [1:M]\)` and `\(i \in [1:N]\)`
]]

--

.pull-right[
.content-box-red[
**Bias correction**
&lt;br&gt;&lt;br&gt;
1. Using pairs `\((\theta_i, \{\theta_j\}_{i=1}^{N})\)` estimate average bias `$$\text{bias} = \mathbb{E}[\mathbb{E}(\theta \vert \tilde{y}_m) - \bar\theta_m]$$`
2. Correct by transformation `$$\theta^\prime = \theta - \text{bias}$$`
]
]

---
class: list-space

## Motivation

.pull-left[
![](index_files/figure-html/bias-plot-1.png)&lt;!-- --&gt;
]

--

.pull-right[
**Questions**


1. Can we correct the variance? *Frequentist*

2. Correct coverage? *Frequentist*

3. Can we correct the entire distribution? **Bayesian**

]

---
class: list-space

## Proper scoring rules

**Scoring rule** `\(S(U,x)\)` compares probabilistic *forecast* `\(U\)` to *ground truth* `\(x\)`.

Define `\(S(U,V) = \mathbb{E}_{x\sim V} S(U,x)\)`, where `\(V\)` is a probability measure.

.content-box-blue[
`\(S(U, \cdot)\)` is **strictly proper** if 
- `\(S(U,U) \geq S(U, V)\)` for all `\(V\)` in some family, and
- equality holds iff `\(U = V\)`.
]

--

.content-box-red[ 

**We use a proper scoring rule:**

`$$\underset{f \in \mathcal{F}}{\arg\max}~\mathbb{E}_{\theta\sim\Pi}\mathbb{E}_{\tilde{y}\sim P(\cdot\vert\theta) }S(f_{\#}\hat\Pi(~\cdot~\vert~\tilde{y}), \theta)$$`
]

`$$~$$`


---
class: list-space

## Bayesian Score Calibration

1. **Generate**
  - Sample `\(M\)` replicates of `\((\bar\theta, \tilde{y}, \hat{\theta}_{1:N})\)` *in parallel*
  - Ground truth, simulated data, posterior
--

2. **Optimise**
  - Find best transformation `\(f\)`
  - Using `\(S\left(f_{\#}\hat\Pi(\cdot~\vert~\tilde{y}),\bar\theta\right)\)` approximated from samples
--

3. **Apply**
  - `\(f\)` to posterior of real data
  - Calculate calibration diagnostics

---
class: list-space

## 1. Generate

.content-box-blue[
$$
\bar\theta^{(m)} \sim \bar\Pi \quad \longrightarrow \quad \tilde{y}^{(m)} \sim P(
\:\cdot\;\vert~\bar\theta^{(m)} ) \quad \longrightarrow \quad \hat\theta^{(m)}_{1:N} \sim \hat{\Pi}(\;\cdot\;\vert \tilde{y}^{(m)})
$$
]

--

- `\(\bar\Pi\)` is an importance distribution to concentrate optimisation 

- `\(P(\:\cdot\;\vert~\bar\theta )\)` is data generating process

- `\(\hat{\Pi}(\;\cdot\;\vert \tilde{y})\)` is our approximate model

---
class: list-space

## 2. Optimise

.content-box-blue[
`$$f^{\star} = \underset{f \in \mathcal{F}}{\arg\max}~ \mathbb{E}\left[w(\bar\theta, \tilde{y})S\left(f_{\#}\hat\Pi(\:\cdot\:\vert\tilde{y}), \bar\theta\right) \right]$$`
]

--

.content-box-red[
`$$f^{\star} \approx \underset{f \in \mathcal{F}}{\arg\max}~ \sum_{m=1}^{M} w(\bar\theta^{(m)}, \tilde{y}^{(m)})S^{N}\left(f_{\#}\hat\Pi(\:\cdot\:\vert\tilde{y}), \bar\theta^{(m)}\right)$$`
]

--

.content-box-green[
**Energy score approximation** with `\(u\sim f_{\#}\hat\Pi(\:\cdot\:\vert\tilde{y})\)` and `\(k\)` is a random permutation vector
`$$S^{N}(U, x) = \frac{1}{N}\sum_{i=1}^{N} \left(\frac{1}{2}\Vert u - u_{k_i} \Vert_2^{\beta} - \Vert u - x \Vert_2^{\beta}\right)$$`
]

`$$~$$`
&lt;br&gt;
`$$~$$`

---
class: list-space

## 3. Apply
&lt;!-- show theory then samples --&gt;

.content-box-blue[
**Adjusted posterior** for observed data `\(y\)`

`$$\theta = f^{\star}(\hat\theta)\quad\text{where}~ \hat\theta \sim \hat\Pi(\cdot \vert y)$$`
]

--

.content-box-red[
**Calibration diagnostic**

`$$\text{CC}(\rho) = \Pr\left\{\bar\theta \in \text{Cr}(f_{\#}^{\star}\hat\Pi(\cdot ~\vert~ \tilde{y}),\rho)\right\},\quad\text{where}~\tilde{y} \sim P( \cdot ~\vert~\bar\theta)$$`

for `\(\rho \in (0,1)\)`. We consider univariate credible regions.

]

--

...with **negligible cost**: (ground truth, approximate posterior) pairs already generated.

---
class: list-space

## Theoretical contribution

- Strictly proper score function `\(S\)` 
- Importance distribution `\(\bar\Pi\)` on `\((\Theta,\vartheta)\)` with `\(\Pi \ll \bar\Pi\)` with density `\(\bar\pi\)`
- Stability function `\(v:\mathsf{Y} \rightarrow [0,\infty)\)`, measurable under `\(P\)` on `\((\mathsf{Y}, \mathcal{Y})\)`
- `\(Q\)` defined by change of measure `\(Q(\text{d} \tilde{y}) \propto P(\text{d} \tilde{y})v(\tilde{y})\)`

--


**Theorem 1**:
.content-box-blue[
If `\(Q\)` has *sufficient support* about `\(y\)` and `\(\mathcal{K}\)` is *sufficiently rich*

then the Markov kernel `\(U^{\star}(\cdot~\vert~\cdot)\)`, defined as

`$$U^{\star}(\cdot~\vert~\cdot) \equiv \underset{U(\cdot~\vert~\cdot) \in \mathcal{K}}{\arg\max}~\mathbb{E}_{\theta \sim \bar\Pi} \mathbb{E}_{\tilde{y} \sim P(\cdot ~\vert~ \theta)}\left[w(\theta, \tilde{y}) S(U(\cdot ~\vert~ \tilde{y}),\theta) \right], \quad w(\theta, \tilde{y}) = \frac{\pi(\theta)}{\bar\pi(\theta)} v(\tilde{y}),$$`

will be equal to the true posterior for the data `\(y\)`, i.e. `\(U^{\star}(\cdot ~\vert~ y) = \Pi(\cdot ~\vert~ y)\)`.
]

---
class: list-space

## Theoretical contribution: Key assumptions

.content-box-blue[
**Sufficiently rich kernel family**

Let `\(\mathcal{K}\)` be a family of non-negative kernels, `\(Q\)` be a probability measure on `\((\mathsf{Y},\mathcal{Y})\)` and `\(\Pi(\cdot ~\vert~\tilde{y})\)` be the true posterior at `\(\tilde{y}\)`. We say `\(\mathcal{K}\)` is sufficiently rich with respect to `\(Q\)` if `\(\Pi(\cdot ~\vert~\tilde{y}) \in \mathcal{K}\)` for all `\(\tilde{y}\)` in the support of `\(Q\)`.
]

--

**For this work we use:** `\(\mathcal{K} = \{f_{\#}\hat\Pi(\cdot~\vert~\cdot):f \in \mathcal{F}\}\)`

--

.content-box-red[
**Sufficient support about the data**

Let `\(Q\)` be a measure on `\((\mathsf{Y},\mathcal{Y})\)` with support at `\(y\)`. We say that `\(Q\)` has sufficient support about `\(y\)` if there exists a neighborhood `\(B_y\)`, centered at `\(y\)`, such that `\(B_y\)` has positive probability under `\(Q\)`, that is `\(Q(B_y) &gt; 0\)`.  
]


---
class: list-space

## What about the weights?

`$$w(\theta, \tilde{y}) = \frac{\pi(\theta)}{\bar\pi(\theta)} v(\tilde{y})$$`

--
- New flexibility from stabilising function `\(v(\tilde{y})\)`

--
- Hard to find `\(v(\tilde{y})\)` such that `\(w(\theta, \tilde{y}) \approx 1\)`

--
- Harder to show finite variance (?)

--

.content-box-blue[
**Clip the weights**

`$$\hat{w}(\theta, \tilde{y}) = \min\{w(\theta, \tilde{y}), q_{1-\alpha}\}$$`

where `\(q_{1-\alpha}\)` is `\((1-\alpha)\)` quantile of raw weights.

]

---
class: list-space

## Transformations for correcting approximate models

--
.content-box-blue[
**Moment-correcting transformation**

`$$f(x) = L[x - \hat{\mu}(y)] + \hat{\mu}(y)+ b$$`
]

--
&lt;br&gt;
- Mean `\(\hat{\mu}(y) = \mathbb{E}(\theta),\quad \theta \sim \hat\Pi(\cdot~\vert~y)\)` for `\(y \in \mathsf{Y}\)`.

--
&lt;br&gt;&lt;br&gt;
- `\(L\)` is a lower triangular matrix with positive elements on diagonal.

---

## Example 1: OU Process (limiting approximation)

.content-box-blue[
`$$\text{d}X_t = \gamma (\mu - X_t) \text{d}t + \sigma\text{d}W_t$$`
]

--

Observe final observation at time `\(T\)` ( `\(n= 100\)`):

--

`$$X_T \sim \mathcal{N}\left(  \mu + (x_0 - \mu)e^{-\gamma T}, \frac{D}{\gamma}(1- e^{-2\gamma T}) \right)$$`

--
where `\(D = \frac{\sigma^2}{2}\)`. Fix `\(\gamma = 2\)`, `\(T=1\)`, `\(x_0 = 10\)`


--
Infer `\(\mu\)` and `\(D\)` with **approximate likelihood** based on

`$$X_\infty  \sim \mathcal{N}\left(\mu, \frac{D}{\gamma}\right)$$`
---

## Example 1: OU Process (limiting approximation)

![](index_files/figure-html/ou-limit-dens-1.png)&lt;!-- --&gt;

`\(M = 100, \beta = 1, \bar\Pi = f_{\#}^{(0,2)}\hat\Pi(\cdot~\vert~y)\)`
---

## Example 1: OU Process (limiting approximation)

.pull-left[
`\(\mu\)`
&lt;table&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:left;"&gt; Method &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; MSE &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; Bias &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; St. Dev &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; Coverage (90%) &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Approx-post &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1.54 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1.21 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.22 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Adjust-post (α=0) &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.12 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.15 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.20 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 64 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Adjust-post (α=0.5) &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.12 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.15 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.23 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 81 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Adjust-post (α=1) &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.12 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.15 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.23 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 82 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; True-post &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.12 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -0.01 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.26 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 94 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
]

.pull-right[
`\(D\)`
&lt;table&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:left;"&gt; Method &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; MSE &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; Bias &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; St. Dev &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; Coverage (90%) &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Approx-post &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 4.73 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.18 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1.46 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 85 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Adjust-post (α=0) &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 4.83 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.28 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1.24 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 72 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Adjust-post (α=0.5) &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 5.08 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.41 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1.42 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 81 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Adjust-post (α=1) &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 5.13 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.42 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1.45 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 83 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; True-post &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 5.00 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.37 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1.48 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 85 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
]

&lt;br&gt;&lt;br&gt;
Estimated from independent replications of the method.

---

## Example 2: Bivariate OU Process (VI approximation)

.content-box-blue[
`$$\text{d}X_t = \gamma (\mu - X_t) \text{d}t + \sigma\text{d}W_t$$`
`$$\text{d}Y_t = \gamma (\mu - Y_t) \text{d}t + \sigma\text{d}W_t$$`
`$$Z_t = \rho X_t + (1-\rho)Y_t$$`
]

Model `\((X_t,Z_t)\)` with setup as in the univariate case, `\((x_0,z_0)=(5,5)\)`.

--

Mean-field **variational approximation**

---

## Example 2: Bivariate OU Process (VI approximation)

.pull-left[
![](index_files/figure-html/ou-vi-contour-1.png)&lt;!-- --&gt;
]

.pull-right[
**Correlation summaries**
&lt;table&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:left;"&gt; Method &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; Mean &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; St. Dev. &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Approx-post &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.00 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.02 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Adjust-post (α=0) &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.18 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.41 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Adjust-post (α=0.5) &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.37 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.16 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Adjust-post (α=1) &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.37 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.15 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; True-post &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.42 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.06 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
]

`\(M = 100, \beta = 1, \bar\Pi = f_{\#}^{(0,2)}\hat\Pi(\cdot~\vert~y)\)`

---

## Example 2: Bivariate OU Process (VI approximation)

![](index_files/figure-html/ou-vi-check-1.png)&lt;!-- --&gt;

---

## Example 3: Whittle likelihood

Fractional ARIMA time series 

.content-box-blue[

**ARFIMA**

`$$\phi(L)(1-L)^d X_t = \vartheta(L)\epsilon_t$$`
`$$\epsilon_t \sim \mathcal{N}(0,\sigma^2)$$`
]


--
`\((p=2, d=0.4, q=1)\)` with `\(n = 15,000\)` observations.


--
Whittle likelihood defines **approximate posterior**.

---

## Example 3: Whittle likelihood

.pull-left[
![](index_files/figure-html/ou-whittle-dens-1.png)&lt;!-- --&gt;
]

.pull-right[
![](index_files/figure-html/ou-whittle-calcheck-1.png)&lt;!-- --&gt;
]

`\(M = 100, \beta = 1, \bar\Pi = f_{\#}^{(0,2)}\hat\Pi(\cdot~\vert~y), L = \text{Diagonal}\)`

---

## Example 4: Lotka-Volterra SDE

.content-box-blue[
**LV-SDE**

`$$\text{d} X_{t} = (\beta_1 X_{t} - \beta_2 X_{t} Y_{t} ) \text{d} t+ \sigma_1 \text{d} B_{t}^{1}$$`
`$$\text{d} Y_{t} = (\beta_4 X_{t} Y_{t} - \beta_3 Y_{t} ) \text{d} t+ \sigma_2 \text{d} B_{t}^{2}$$`
]


--
Use noisy quasi-likelihood as **approximate model**

`$$L(\beta_{1:4}, \tau ~\vert~ x_{1:n}, y_{1:n}) = \tau^{2n}\exp\left(-\frac{\tau^2}{2} \sum_{i=1}^{n}\left[(x_i^\prime - x_i)^{2} + (y_i^\prime - y_i)^{2}\right] \right)$$`
where are `\(\{(x_i^\prime,y_i^\prime)\}_{i=1}^{n}\)` simulated conditional on parameters and `\(\tau ∼ \text{Gamma}(2, 3)\)`.


--
**Further approximation**: use rough numerical integration scheme (Euler-Maruyama `\(\Delta t=0.01\)`).

---

## Example 4: Lotka-Volterra SDE

.pull-left[
![](index_files/figure-html/ou-lv-dens-1.png)&lt;!-- --&gt;
]

.pull-right[
![](index_files/figure-html/ou-lv-calcheck-1.png)&lt;!-- --&gt;
]

`\(M = 200, \beta = 1, \bar\Pi = f_{\#}^{(0,2)}\hat\Pi(\cdot~\vert~y), \sigma_1=\sigma_2=0.1\)` with observation times `\(t \in \{0, 0.1, 0.2, \ldots, 9.9, 10\}\)`

---
class: list-space

## Caveats/Limitations

--
- Some regularisation useful for dependent-multivariate transformations of posteriors

--
&lt;br&gt;&lt;br&gt;&lt;br&gt;
- Results are *targeted* towards `\(\bar\Pi\)` 
  - finite sample approximation

--
&lt;br&gt;&lt;br&gt;&lt;br&gt;
- Even more *targeted* when manipulating the weights
  - insufficiency of moment-correcting transformation with approximate posterior


---

## Justification of unit weights

When we take `\(\alpha =1\)`, `\(\hat{w} = 1\)`!

--

.content-box-blue[
**Theorem 2**

Let `\(g(x) = \bar \pi(x) / \pi(x)\)` for `\(x \in \Theta\)`. 

- If an estimator `\(\theta^{\ast}_n \equiv \theta^{\ast}(\tilde{y}_{1:n})\)` exists such that  `\(\theta^{\ast}_n \rightarrow z\)` a.s. for `\(n \rightarrow \infty\)` when `\(\tilde{y}_i \sim P(\cdot ~\vert~ z)\)` for `\(z \in \Theta\)`,

- If `\(g\)` is positive and continuous at `\(z\)` then the error when using `\(\hat{w} = 1\)` satisfies
`$$\hat{w} - w(\theta,\tilde{y}_{1:n}) \rightarrow 0$$` 
a.s. for `\(n \rightarrow \infty\)`
]

--

And a CLT for unit weights appears in our paper.

---

## Justification of unit weights

Theorem 2 is possible because of the stability function justified by Theorem 1.

.content-box-blue[
`$$w(\theta, \tilde{y}) = \frac{\pi(\theta)}{\bar\pi(\theta)} v(\tilde{y})$$`
]

--

**Trick**: set `\(v(\tilde{y}) = \frac{\bar\pi(\theta^{\ast}_n )}{\pi(\theta^{\ast}_n )}\)` and look at large sample properties.

--

Don't need to explicitly know the estimator `\(\theta^{\ast}_n\)`!

---
class: list-space

## Current and future work

--
- Apply to chemical reaction networks with coarse ABC-type approximate posterior

--
- Apply to agent-based models (e.g. SIR, biological cells) with ODE-based approximate posterior

--
- Try with Pareto-smoothed weights (Vehtari et al, 2022)

--
- Use flexibility of `\(v(\tilde{y})\)` to obtain `\(w(\theta, \tilde{y}) \approx 1\)` to control weights in 
  - SNP-style algorithms
  - Generative neural networks (Pacchiardi &amp; Dutta, 2022)



---
class: inverse, center, middle, hide-logo

## Thank you for listening 🏂
&lt;br&gt;&lt;br&gt;&lt;br&gt;
https://arxiv.org/abs/2211.05357
&lt;br&gt;&lt;br&gt; @bonstats 
&lt;br&gt;&lt;br&gt; @bon@bayes.club
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"slideNumberFormat": "%current%",
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false,
"ratio": "16:9"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>
<style>
.logo {
  background-image: url(imgs/QUT_SQUARE_RGB_XLGE.png);
  background-size: contain;
  background-repeat: no-repeat;
  position: absolute;
  top: 1em;
  right: 1em;
  width: 100px;
  height: 100px;
  z-index: 0;
}
</style>

<script>
document
  .querySelectorAll(
    '.remark-slide-content' +
    ':not(.title-slide)' +
    // add additional classes to exclude here, e.g.
    // ':not(.inverse)' +
    ':not(.hide-logo)'
  )
  .forEach(el => {
    el.innerHTML += '<div class="logo"></div>';
  });
</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
